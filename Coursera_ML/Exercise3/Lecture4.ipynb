{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "from scipy.io import loadmat\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorized cost function for Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lrCostFunction(theta, X, y, lambda_):\n",
    "    #Initialize some useful values\n",
    "    m = y.size\n",
    "    aux = sigmoid(X@theta)\n",
    "    theta = theta.copy()\n",
    "    theta[0] = 0\n",
    "    \n",
    "    # convert labels to ints if their type is bool\n",
    "    if y.dtype == bool:\n",
    "        y = y.astype(int)\n",
    "    \n",
    "    #J:\n",
    "    J = (-y@np.log(aux) - (1-y)@np.log(1-aux))/m + lambda_*theta@theta/(2*m)\n",
    "\n",
    "    #grad\n",
    "    grad = X.transpose()@(aux-y)/m + lambda_*theta/m\n",
    "        \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One vs All classification:\n",
    "Remember that in one vs all classification we are comparing one hypothesis applied to an input to all the other classifications, and we choose the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def oneVsAll(X, y, num_labels, lambda_):\n",
    "    #We expect X as a matrix, y as a vector and this returns\n",
    "    #a matrix with all the thetas as rows\n",
    "    ##\n",
    "    # Some useful variables\n",
    "    m, n = X.shape\n",
    "    \n",
    "    # You need to return the following variables correctly \n",
    "    all_theta = np.zeros((num_labels, n + 1))\n",
    "    initial_theta = np.zeros(X.shape[1]+1)\n",
    "    \n",
    "    # Add ones to the X data matrix\n",
    "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "    \n",
    "    options = {'maxiter': 50}\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    for i in range(num_labels):\n",
    "        res = optimize.minimize(lrCostFunction, \n",
    "                        initial_theta, \n",
    "                        (X, (y == i), lambda_), \n",
    "                        jac=True, \n",
    "                        method='TNC',\n",
    "                        options=options)\n",
    "        all_theta[i,:] = res.x\n",
    "\n",
    "    # ============================================================\n",
    "    return all_theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictOneVsAll(all_theta, X):\n",
    "    \n",
    "    m = X.shape[0];\n",
    "    num_labels = all_theta.shape[0]\n",
    "    \n",
    "    # Add ones to the X data matrix\n",
    "    X = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "\n",
    "    p = (all_theta@X.transpose()).argmax(axis=0)\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network:\n",
    "Here we are going to develop a forward propagation given that we already have a trained neural network. The specific architecture of this neural network has 3 layers. With 400 input layers units, 25 input layers in the second layer and 10 in the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup the parameters you will use for this exercise\n",
    "input_layer_size  = 400  # 20x20 Input Images of Digits\n",
    "hidden_layer_size = 25   # 25 hidden units\n",
    "num_labels = 10          # 10 labels, from 0 to 9\n",
    "\n",
    "# Load the .mat file, which returns a dictionary \n",
    "weights = loadmat(os.path.join('Data', 'ex3weights.mat'))\n",
    "\n",
    "# get the model weights from the dictionary\n",
    "# Theta1 has size 25 x 401\n",
    "# Theta2 has size 10 x 26\n",
    "Theta1, Theta2 = weights['Theta1'], weights['Theta2']\n",
    "\n",
    "# swap first and last columns of Theta2, due to legacy from MATLAB indexing, \n",
    "# since the weight file ex3weights.mat was saved based on MATLAB indexing\n",
    "Theta2 = np.roll(Theta2, 1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 97.5%\n"
     ]
    }
   ],
   "source": [
    "def predict(Theta1, Theta2, X):\n",
    "    # Make sure the input has two dimensions\n",
    "\n",
    "    if X.ndim == 1:\n",
    "        X = X[None]  # promote to 2-dimensions\n",
    "    \n",
    "    # useful variables\n",
    "    m = X.shape[0]\n",
    "    num_labels = Theta2.shape[0]\n",
    "\n",
    "    # You need to return the following variables correctly \n",
    "    p = np.zeros(X.shape[0])\n",
    "\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    x_1 = np.append(np.ones((m,1)),X,axis=1)\n",
    "    snd_row = sigmoid(Theta1@x_1.transpose())\n",
    "    \n",
    "    w = snd_row.shape[1]\n",
    "    ones = np.ones(w)[np.newaxis]\n",
    "    x_2 = np.concatenate([ones,snd_row])\n",
    "    \n",
    "    p = sigmoid(Theta2@x_2).argmax(axis=0)\n",
    "    \n",
    "    # =============================================================\n",
    "    return p\n",
    "\n",
    "pred = predict(Theta1, Theta2, X)\n",
    "print('Training Set Accuracy: {:.1f}%'.format(np.mean(pred == y) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main takeaways from Numpy in this lesson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#array,num_values,replace = True(bootstrap or not),probability of each)\n",
    "a = np.arange(1,10,2)\n",
    "np.random.choice(a,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = np.arange(10).reshape(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4],\n",
       "       [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 5],\n",
       "       [1, 6],\n",
       "       [2, 7],\n",
       "       [3, 8],\n",
       "       [4, 9]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#faster way to transpose: .T\n",
    "w.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
